{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "495bfebf-1ee5-4e12-9644-87e0f74a3016",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pickle\n",
    "import copy\n",
    "import torch\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel\n",
    "from itertools import combinations\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from console1 import generate_partition\n",
    "from model import BertClassifier\n",
    "\n",
    "# F_P = {\n",
    "#     0: [0,1],\n",
    "#     1: [2,3],\n",
    "#     2: [4,5,6,7,8,9,10,11],\n",
    "#     3: [12,13],\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9700d484-bdd5-45f7-9402-eaadd04bf64b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       X_-TACT_TIME_mean  X_-CONVEYOR_SPEED_mean    PUMP_high  PUMP_low  \\\n",
      "16010                150                    3150  37494.28000  12305.50   \n",
      "19201                165                    4200  38257.14000  12518.56   \n",
      "21232                140                    3150  45430.73333   9255.75   \n",
      "33991                160                    3150  47262.94000  12518.58   \n",
      "25200                170                    3150  49986.46667  12039.14   \n",
      "\n",
      "       CLN1_over-etching-ratio  CLN1_EPT_time  clean_count  \\\n",
      "16010                 0.002079          12987            5   \n",
      "19201                 0.006691          13002            5   \n",
      "21232                 0.004852          12984            5   \n",
      "33991                 0.002744          12027            5   \n",
      "25200                 0.000750          12000            7   \n",
      "\n",
      "       EPT_clean_count_ratio  NH3_TREAT_-RF_FREQ-max  \\\n",
      "16010            2597.400000                   13970   \n",
      "19201            2600.400000                   13935   \n",
      "21232            2596.800000                   13961   \n",
      "33991            2405.400000                   13979   \n",
      "25200            1714.285714                   13975   \n",
      "\n",
      "       NH3_TREAT_-RF_FREQ-range  NH3_TREAT_-RF_FREQ-mean  \\\n",
      "16010                       441               13639.2500   \n",
      "19201                       406               13647.7857   \n",
      "21232                       449               13615.6154   \n",
      "33991                       471               13634.5000   \n",
      "25200                       449               13638.2500   \n",
      "\n",
      "       NP_3_-MFC_VOL_SIH4-range    VENT_high     VENT_low  \n",
      "16010                         1  17631.92857  7409.445455  \n",
      "19201                         1  16703.71765  8878.433333  \n",
      "21232                         1  16116.29444  8813.845455  \n",
      "33991                         1  16557.55882  8937.611111  \n",
      "25200                         1  19001.35385  7457.881818  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data_with_output.csv')\n",
    "df = df.drop(columns=['Output'])\n",
    "df_mean = df.mean()\n",
    "df_std = df.std()\n",
    "sample_df = pd.read_csv('sampled_df100.csv',index_col=0)\n",
    "print(sample_df.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11c2248a-3c55-4b27-9bed-3e1e3e5dfb6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "u_set = [i for i in range(14)]\n",
    "consider1 = [0,1,6,7,8,9,10]\n",
    "leng = [i for i in range(1,len(consider1)+1)]\n",
    "consider_combine1 =sum(list(list(combinations(consider1,r)) for r in leng),[])\n",
    "consider_combine_c1 = [tuple(set(u_set)-set(comb)) for comb in consider_combine1]\n",
    "all_feature_dict1 = []\n",
    "for idx in range(len(consider_combine1)):\n",
    "    feature_dict = {}\n",
    "    feature_dict[0] = list(consider_combine1[idx])\n",
    "    feature_dict[1] = list(consider_combine_c1[idx])\n",
    "    all_feature_dict1.append(feature_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bb19299",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_set = [i for i in range(14)]\n",
    "consider = [0,1,2,4,5,6,7,8,9,10]\n",
    "leng = [i for i in range(1,4)]\n",
    "consider_combine0 =sum(list(list(combinations(consider,r)) for r in leng),[])\n",
    "consider_combine = list(set(consider_combine0) - set(consider_combine1))\n",
    "consider_combine.append((3,))\n",
    "consider_combine.append((11,))\n",
    "consider_combine.append((12,))\n",
    "consider_combine.append((13,))\n",
    "consider_combine_c = [tuple(set(u_set)-set(comb)) for comb in consider_combine]\n",
    "all_feature_dict = []\n",
    "for idx in range(len(consider_combine)):\n",
    "    feature_dict = {}\n",
    "    feature_dict[0] = list(consider_combine[idx])\n",
    "    feature_dict[1] = list(consider_combine_c[idx])\n",
    "    all_feature_dict.append(feature_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fbfd4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feature_dict = sorted(all_feature_dict, key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3767b812-78b6-4b2d-929f-8e6eb334767a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EQ': ['X_-TACT_TIME_mean', 'X_-CONVEYOR_SPEED_mean'], 'PUMP': ['PUMP_high', 'PUMP_low'], 'CH': ['CLN1_over-etching-ratio', 'CLN1_EPT_time', 'clean_count', 'EPT_clean_count_ratio', 'NH3_TREAT_-RF_FREQ-max', 'NH3_TREAT_-RF_FREQ-range', 'NH3_TREAT_-RF_FREQ-mean', 'NP_3_-MFC_VOL_SIH4-range'], 'VENT': ['VENT_high', 'VENT_low'], 'y': 'Output'}\n",
      "['X_-TACT_TIME_mean', 'X_-CONVEYOR_SPEED_mean', 'PUMP_high', 'PUMP_low', 'CLN1_over-etching-ratio', 'CLN1_EPT_time', 'clean_count', 'EPT_clean_count_ratio', 'NH3_TREAT_-RF_FREQ-max', 'NH3_TREAT_-RF_FREQ-range', 'NH3_TREAT_-RF_FREQ-mean', 'NP_3_-MFC_VOL_SIH4-range', 'VENT_high', 'VENT_low', 'Output']\n",
      "There are 4 sub processes. So the feature translation is [(0, 0), (0, 1), (1, 2), (1, 3), (2, 4), (2, 5), (2, 6), (2, 7), (2, 8), (2, 9), (2, 10), (2, 11), (3, 12), (3, 13)]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "s1_model_path = 'stage_1_checkpoint.pth'\n",
    "s1_model =  torch.load(s1_model_path, map_location=device).to(device)\n",
    "json_file_path = 'controllable_para_v014_14.json'\n",
    "tool_name = 'ASCVD'\n",
    "with open(json_file_path, 'r') as f:\n",
    "    params = json.load(f)[tool_name]\n",
    "    print(params)\n",
    "    f.close()\n",
    "target_features = []\n",
    "\n",
    "''' \n",
    "    The feature_translation is a list of tuples, each tuple contains two integers.\n",
    "    The tuples record the correponding position of the ith feature in the 4*freature matrix\n",
    "    as the input the prediction model.\n",
    "    Ex.\n",
    "    [(0, 0), (0, 1), \n",
    "     (1, 2), (1, 3), \n",
    "     (2, 4), (2, 5), (2, 6), (2, 7), (2, 8), (2, 9), (2, 10), (2, 11), \n",
    "     (3, 12),(3, 13)]\n",
    "'''\n",
    "# Flat the feature list and construct teh freature translation list to map feature into the input of the model\n",
    "feature_translation = []\n",
    "sub_op_num = 0\n",
    "for entry in [sub_op for _, sub_op in params.items()]:\n",
    "    if isinstance(entry, str):\n",
    "        target_features.append(entry)\n",
    "    else:\n",
    "        target_features.extend(entry)\n",
    "        feature_translation.extend([(sub_op_num,len(feature_translation)+j) for j in range(len(entry))])\n",
    "        sub_op_num = sub_op_num+1 \n",
    "\n",
    "print(target_features)\n",
    "print(f\"There are {sub_op_num} sub processes. So the feature translation is {feature_translation}\")\n",
    "\n",
    "def padding_zero(df, flag): \n",
    "    # 將一維參數matrix擴展為4維\n",
    "    data_arr = df.to_numpy()\n",
    "    result = []\n",
    "    for data in data_arr:\n",
    "        empty_arr = np.zeros((sub_op_num, len(feature_translation))) # chamber數 * 總參數數量\n",
    "        for i, pos in enumerate(feature_translation):\n",
    "            empty_arr[pos[0]][pos[1]] = data[i]\n",
    "        if(flag == 1): # bert.py使用\n",
    "            result.append(empty_arr)\n",
    "        if(flag == 2): # bert_du.py使用\n",
    "            result.append(empty_arr.tolist())\n",
    "    \n",
    "    if(flag == 1): # bert.py使用\n",
    "        result = pd.DataFrame({'X': [result[i] for i in range(len(result))]})\n",
    "    return result\n",
    "\n",
    "def model_inference(data):  #standardize dataframe\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    s1_model.eval()\n",
    "    # scaler = StandardScaler()\n",
    "    if 'Output' in data.columns:\n",
    "        data = data.drop(columns=['Output'])\n",
    "    # data_standardized_df = pd.DataFrame(scaler.fit_transform(data))\n",
    "    #print(data.head())\n",
    "    #print(f'Standardized data:\\n{data_standardized_df.head(3)}')  # Debug\n",
    "    \n",
    "    data_4d = padding_zero(data,flag=1)\n",
    "    \n",
    "    #print(f'4D data:\\n{data_4d.head()}')  # Debug\n",
    "    \n",
    "    data_4d_array = np.array([e for entry in data_4d.values for e in entry])\n",
    "    data_4d_tensor = torch.tensor(data_4d_array,dtype=torch.float)\n",
    "    \n",
    "    #print(f'Tensor data shape: {data_4d_tensor.shape}')  # Debug \n",
    "    \n",
    "    my_dataset = TensorDataset(data_4d_tensor)\n",
    "    batch_size = min(256, int(data_4d_tensor.size()[0]))\n",
    "    my_loader = DataLoader(my_dataset, batch_size=batch_size,num_workers=2)\n",
    "    data_output = []\n",
    "    with torch.no_grad():\n",
    "        for batch_data in my_loader:\n",
    "        # 将数据移到指定的设备上（如 CUDA 设备）\n",
    "            batch_data = batch_data[0].to(device)\n",
    "        # 将数据传递给模型进行推理\n",
    "            batch_output = s1_model(batch_data)\n",
    "            probs = (torch.nn.functional.softmax(batch_output, dim=1))\n",
    "        # 将输出保存起来\n",
    "            data_output += probs\n",
    "    data_output_array = np.array([output.cpu().numpy()[0] for output in data_output])\n",
    "    data_expectation_value = data_output_array.mean()\n",
    "    return data_expectation_value, data_output_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a0ab578-5335-41f1-bd3f-0a68977c5ccc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 過濾掉FutureWarning\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# First, calculate the output mean of the experiment data\n",
    "# base_mean, details = model_inference(s_df)\n",
    "# print(f'Base mean: {base_mean}')\n",
    "# creat dataframe for saving vertex value\n",
    "# import pickle\n",
    "\n",
    "# # Open the pickle file in binary read mode\n",
    "# with open('savedata/E_vi_20240612.pkl', 'rb') as f:\n",
    "#     # Load the data from the file\n",
    "#     data = pickle.load(f)\n",
    "\n",
    "# # The data is now available in the 'data' variable\n",
    "# print(data.shape)\n",
    "# vertex_df = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c93146ab-8a35-42df-a02d-0b1d0b188149",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now running [0, 1, 2]\n",
      "gen 100 vertex\n",
      "gen 200 vertex\n",
      "[0, 1, 2] done\n",
      "now running [0, 1, 4]\n",
      "gen 300 vertex\n",
      "gen 400 vertex\n",
      "[0, 1, 4] done\n",
      "now running [0, 1, 5]\n",
      "gen 500 vertex\n",
      "gen 600 vertex\n",
      "[0, 1, 5] done\n",
      "now running [0, 2]\n",
      "gen 700 vertex\n",
      "gen 800 vertex\n",
      "[0, 2] done\n",
      "now running [0, 2, 4]\n",
      "gen 900 vertex\n",
      "gen 1000 vertex\n",
      "[0, 2, 4] done\n",
      "now running [0, 2, 5]\n",
      "gen 1100 vertex\n",
      "gen 1200 vertex\n",
      "[0, 2, 5] done\n",
      "now running [0, 2, 6]\n",
      "gen 1300 vertex\n",
      "gen 1400 vertex\n",
      "[0, 2, 6] done\n",
      "now running [0, 2, 7]\n",
      "gen 1500 vertex\n",
      "gen 1600 vertex\n",
      "[0, 2, 7] done\n",
      "now running [0, 2, 8]\n",
      "gen 1700 vertex\n",
      "gen 1800 vertex\n",
      "[0, 2, 8] done\n",
      "now running [0, 2, 9]\n",
      "gen 1900 vertex\n",
      "gen 2000 vertex\n",
      "[0, 2, 9] done\n",
      "now running [0, 2, 10]\n",
      "gen 2100 vertex\n",
      "gen 2200 vertex\n",
      "[0, 2, 10] done\n",
      "now running [0, 4]\n",
      "gen 2300 vertex\n",
      "gen 2400 vertex\n",
      "[0, 4] done\n",
      "now running [0, 4, 5]\n",
      "gen 2500 vertex\n",
      "gen 2600 vertex\n",
      "[0, 4, 5] done\n",
      "now running [0, 4, 6]\n",
      "gen 2700 vertex\n",
      "gen 2800 vertex\n",
      "[0, 4, 6] done\n",
      "now running [0, 4, 7]\n",
      "gen 2900 vertex\n",
      "gen 3000 vertex\n",
      "[0, 4, 7] done\n",
      "now running [0, 4, 8]\n",
      "gen 3100 vertex\n",
      "gen 3200 vertex\n",
      "[0, 4, 8] done\n",
      "now running [0, 4, 9]\n",
      "gen 3300 vertex\n",
      "gen 3400 vertex\n",
      "[0, 4, 9] done\n",
      "now running [0, 4, 10]\n",
      "gen 3500 vertex\n",
      "gen 3600 vertex\n",
      "[0, 4, 10] done\n",
      "now running [0, 5]\n",
      "gen 3700 vertex\n",
      "gen 3800 vertex\n",
      "[0, 5] done\n",
      "now running [0, 5, 6]\n",
      "gen 3900 vertex\n",
      "gen 4000 vertex\n",
      "[0, 5, 6] done\n",
      "now running [0, 5, 7]\n",
      "gen 4100 vertex\n",
      "gen 4200 vertex\n",
      "[0, 5, 7] done\n",
      "now running [0, 5, 8]\n",
      "gen 4300 vertex\n",
      "gen 4400 vertex\n",
      "[0, 5, 8] done\n",
      "now running [0, 5, 9]\n",
      "gen 4500 vertex\n",
      "gen 4600 vertex\n",
      "[0, 5, 9] done\n",
      "now running [0, 5, 10]\n",
      "gen 4700 vertex\n",
      "gen 4800 vertex\n",
      "[0, 5, 10] done\n",
      "now running [1, 2]\n",
      "gen 4900 vertex\n",
      "gen 5000 vertex\n",
      "[1, 2] done\n",
      "now running [1, 2, 4]\n",
      "gen 5100 vertex\n",
      "gen 5200 vertex\n",
      "[1, 2, 4] done\n",
      "now running [1, 2, 5]\n",
      "gen 5300 vertex\n",
      "gen 5400 vertex\n",
      "[1, 2, 5] done\n",
      "now running [1, 2, 6]\n",
      "gen 5500 vertex\n",
      "gen 5600 vertex\n",
      "[1, 2, 6] done\n",
      "now running [1, 2, 7]\n",
      "gen 5700 vertex\n",
      "gen 5800 vertex\n",
      "[1, 2, 7] done\n",
      "now running [1, 2, 8]\n",
      "gen 5900 vertex\n",
      "gen 6000 vertex\n",
      "[1, 2, 8] done\n",
      "now running [1, 2, 9]\n",
      "gen 6100 vertex\n",
      "gen 6200 vertex\n",
      "[1, 2, 9] done\n",
      "now running [1, 2, 10]\n",
      "gen 6300 vertex\n",
      "gen 6400 vertex\n",
      "[1, 2, 10] done\n",
      "now running [1, 4]\n",
      "gen 6500 vertex\n",
      "gen 6600 vertex\n",
      "[1, 4] done\n",
      "now running [1, 4, 5]\n",
      "gen 6700 vertex\n",
      "gen 6800 vertex\n",
      "[1, 4, 5] done\n",
      "now running [1, 4, 6]\n",
      "gen 6900 vertex\n",
      "gen 7000 vertex\n",
      "[1, 4, 6] done\n",
      "now running [1, 4, 7]\n",
      "gen 7100 vertex\n",
      "gen 7200 vertex\n",
      "[1, 4, 7] done\n",
      "now running [1, 4, 8]\n",
      "gen 7300 vertex\n",
      "gen 7400 vertex\n",
      "[1, 4, 8] done\n",
      "now running [1, 4, 9]\n",
      "gen 7500 vertex\n",
      "gen 7600 vertex\n",
      "[1, 4, 9] done\n",
      "now running [1, 4, 10]\n",
      "gen 7700 vertex\n",
      "gen 7800 vertex\n",
      "[1, 4, 10] done\n",
      "now running [1, 5]\n",
      "gen 7900 vertex\n",
      "gen 8000 vertex\n",
      "[1, 5] done\n",
      "now running [1, 5, 6]\n",
      "gen 8100 vertex\n",
      "gen 8200 vertex\n",
      "[1, 5, 6] done\n",
      "now running [1, 5, 7]\n",
      "gen 8300 vertex\n",
      "gen 8400 vertex\n",
      "[1, 5, 7] done\n",
      "now running [1, 5, 8]\n",
      "gen 8500 vertex\n",
      "gen 8600 vertex\n",
      "[1, 5, 8] done\n",
      "now running [1, 5, 9]\n",
      "gen 8700 vertex\n",
      "gen 8800 vertex\n",
      "[1, 5, 9] done\n",
      "now running [1, 5, 10]\n",
      "gen 8900 vertex\n",
      "gen 9000 vertex\n",
      "[1, 5, 10] done\n",
      "now running [2]\n",
      "gen 9100 vertex\n",
      "gen 9200 vertex\n",
      "[2] done\n",
      "now running [2, 4]\n",
      "gen 9300 vertex\n",
      "gen 9400 vertex\n",
      "[2, 4] done\n",
      "now running [2, 4, 5]\n",
      "gen 9500 vertex\n",
      "gen 9600 vertex\n",
      "[2, 4, 5] done\n",
      "now running [2, 4, 6]\n",
      "gen 9700 vertex\n",
      "gen 9800 vertex\n",
      "[2, 4, 6] done\n",
      "now running [2, 4, 7]\n",
      "gen 9900 vertex\n",
      "gen 10000 vertex\n",
      "[2, 4, 7] done\n",
      "now running [2, 4, 8]\n",
      "gen 10100 vertex\n",
      "gen 10200 vertex\n",
      "[2, 4, 8] done\n",
      "now running [2, 4, 9]\n",
      "gen 10300 vertex\n",
      "gen 10400 vertex\n",
      "[2, 4, 9] done\n",
      "now running [2, 4, 10]\n",
      "gen 10500 vertex\n",
      "gen 10600 vertex\n",
      "[2, 4, 10] done\n",
      "now running [2, 5]\n",
      "gen 10700 vertex\n",
      "gen 10800 vertex\n",
      "[2, 5] done\n",
      "now running [2, 5, 6]\n",
      "gen 10900 vertex\n",
      "gen 11000 vertex\n",
      "[2, 5, 6] done\n",
      "now running [2, 5, 7]\n",
      "gen 11100 vertex\n",
      "gen 11200 vertex\n",
      "[2, 5, 7] done\n",
      "now running [2, 5, 8]\n",
      "gen 11300 vertex\n",
      "gen 11400 vertex\n",
      "[2, 5, 8] done\n",
      "now running [2, 5, 9]\n",
      "gen 11500 vertex\n",
      "gen 11600 vertex\n",
      "[2, 5, 9] done\n",
      "now running [2, 5, 10]\n",
      "gen 11700 vertex\n",
      "gen 11800 vertex\n",
      "[2, 5, 10] done\n",
      "now running [2, 6]\n",
      "gen 11900 vertex\n",
      "gen 12000 vertex\n",
      "[2, 6] done\n",
      "now running [2, 6, 7]\n",
      "gen 12100 vertex\n",
      "gen 12200 vertex\n",
      "[2, 6, 7] done\n",
      "now running [2, 6, 8]\n",
      "gen 12300 vertex\n",
      "gen 12400 vertex\n",
      "[2, 6, 8] done\n",
      "now running [2, 6, 9]\n",
      "gen 12500 vertex\n",
      "gen 12600 vertex\n",
      "[2, 6, 9] done\n",
      "now running [2, 6, 10]\n",
      "gen 12700 vertex\n",
      "gen 12800 vertex\n",
      "[2, 6, 10] done\n",
      "now running [2, 7]\n",
      "gen 12900 vertex\n",
      "gen 13000 vertex\n",
      "[2, 7] done\n",
      "now running [2, 7, 8]\n",
      "gen 13100 vertex\n",
      "gen 13200 vertex\n",
      "[2, 7, 8] done\n",
      "now running [2, 7, 9]\n",
      "gen 13300 vertex\n",
      "gen 13400 vertex\n",
      "[2, 7, 9] done\n",
      "now running [2, 7, 10]\n",
      "gen 13500 vertex\n",
      "gen 13600 vertex\n",
      "[2, 7, 10] done\n",
      "now running [2, 8]\n",
      "gen 13700 vertex\n",
      "gen 13800 vertex\n",
      "[2, 8] done\n",
      "now running [2, 8, 9]\n",
      "gen 13900 vertex\n",
      "gen 14000 vertex\n",
      "[2, 8, 9] done\n",
      "now running [2, 8, 10]\n",
      "gen 14100 vertex\n",
      "gen 14200 vertex\n",
      "[2, 8, 10] done\n",
      "now running [2, 9]\n",
      "gen 14300 vertex\n",
      "gen 14400 vertex\n",
      "[2, 9] done\n",
      "now running [2, 9, 10]\n",
      "gen 14500 vertex\n",
      "gen 14600 vertex\n",
      "[2, 9, 10] done\n",
      "now running [2, 10]\n",
      "gen 14700 vertex\n",
      "gen 14800 vertex\n",
      "[2, 10] done\n",
      "now running [3]\n",
      "gen 14900 vertex\n",
      "gen 15000 vertex\n",
      "[3] done\n",
      "now running [4]\n",
      "gen 15100 vertex\n",
      "gen 15200 vertex\n",
      "[4] done\n",
      "now running [4, 5]\n",
      "gen 15300 vertex\n",
      "gen 15400 vertex\n",
      "[4, 5] done\n",
      "now running [4, 5, 6]\n",
      "gen 15500 vertex\n",
      "gen 15600 vertex\n",
      "[4, 5, 6] done\n",
      "now running [4, 5, 7]\n",
      "gen 15700 vertex\n",
      "gen 15800 vertex\n",
      "[4, 5, 7] done\n",
      "now running [4, 5, 8]\n",
      "gen 15900 vertex\n",
      "gen 16000 vertex\n",
      "[4, 5, 8] done\n",
      "now running [4, 5, 9]\n",
      "gen 16100 vertex\n",
      "gen 16200 vertex\n",
      "[4, 5, 9] done\n",
      "now running [4, 5, 10]\n",
      "gen 16300 vertex\n",
      "gen 16400 vertex\n",
      "[4, 5, 10] done\n",
      "now running [4, 6]\n",
      "gen 16500 vertex\n",
      "gen 16600 vertex\n",
      "[4, 6] done\n",
      "now running [4, 6, 7]\n",
      "gen 16700 vertex\n",
      "gen 16800 vertex\n",
      "[4, 6, 7] done\n",
      "now running [4, 6, 8]\n",
      "gen 16900 vertex\n",
      "gen 17000 vertex\n",
      "[4, 6, 8] done\n",
      "now running [4, 6, 9]\n",
      "gen 17100 vertex\n",
      "gen 17200 vertex\n",
      "[4, 6, 9] done\n",
      "now running [4, 6, 10]\n",
      "gen 17300 vertex\n",
      "gen 17400 vertex\n",
      "[4, 6, 10] done\n",
      "now running [4, 7]\n",
      "gen 17500 vertex\n",
      "gen 17600 vertex\n",
      "[4, 7] done\n",
      "now running [4, 7, 8]\n",
      "gen 17700 vertex\n",
      "gen 17800 vertex\n",
      "[4, 7, 8] done\n",
      "now running [4, 7, 9]\n",
      "gen 17900 vertex\n",
      "gen 18000 vertex\n",
      "[4, 7, 9] done\n",
      "now running [4, 7, 10]\n",
      "gen 18100 vertex\n",
      "gen 18200 vertex\n",
      "[4, 7, 10] done\n",
      "now running [4, 8]\n",
      "gen 18300 vertex\n",
      "gen 18400 vertex\n",
      "[4, 8] done\n",
      "now running [4, 8, 9]\n",
      "gen 18500 vertex\n",
      "gen 18600 vertex\n",
      "[4, 8, 9] done\n",
      "now running [4, 8, 10]\n",
      "gen 18700 vertex\n",
      "gen 18800 vertex\n",
      "[4, 8, 10] done\n",
      "now running [4, 9]\n",
      "gen 18900 vertex\n",
      "gen 19000 vertex\n",
      "[4, 9] done\n",
      "now running [4, 9, 10]\n",
      "gen 19100 vertex\n",
      "gen 19200 vertex\n",
      "[4, 9, 10] done\n",
      "now running [4, 10]\n",
      "gen 19300 vertex\n",
      "gen 19400 vertex\n",
      "[4, 10] done\n",
      "now running [5]\n",
      "gen 19500 vertex\n",
      "gen 19600 vertex\n",
      "[5] done\n",
      "now running [5, 6]\n",
      "gen 19700 vertex\n",
      "gen 19800 vertex\n",
      "[5, 6] done\n",
      "now running [5, 6, 7]\n",
      "gen 19900 vertex\n",
      "gen 20000 vertex\n",
      "[5, 6, 7] done\n",
      "now running [5, 6, 8]\n",
      "gen 20100 vertex\n",
      "gen 20200 vertex\n",
      "[5, 6, 8] done\n",
      "now running [5, 6, 9]\n",
      "gen 20300 vertex\n",
      "gen 20400 vertex\n",
      "[5, 6, 9] done\n",
      "now running [5, 6, 10]\n",
      "gen 20500 vertex\n",
      "gen 20600 vertex\n",
      "[5, 6, 10] done\n",
      "now running [5, 7]\n",
      "gen 20700 vertex\n",
      "gen 20800 vertex\n",
      "[5, 7] done\n",
      "now running [5, 7, 8]\n",
      "gen 20900 vertex\n",
      "gen 21000 vertex\n",
      "[5, 7, 8] done\n",
      "now running [5, 7, 9]\n",
      "gen 21100 vertex\n",
      "gen 21200 vertex\n",
      "[5, 7, 9] done\n",
      "now running [5, 7, 10]\n",
      "gen 21300 vertex\n",
      "gen 21400 vertex\n",
      "[5, 7, 10] done\n",
      "now running [5, 8]\n",
      "gen 21500 vertex\n",
      "gen 21600 vertex\n",
      "[5, 8] done\n",
      "now running [5, 8, 9]\n",
      "gen 21700 vertex\n",
      "gen 21800 vertex\n",
      "[5, 8, 9] done\n",
      "now running [5, 8, 10]\n",
      "gen 21900 vertex\n",
      "gen 22000 vertex\n",
      "[5, 8, 10] done\n",
      "now running [5, 9]\n",
      "gen 22100 vertex\n",
      "gen 22200 vertex\n",
      "[5, 9] done\n",
      "now running [5, 9, 10]\n",
      "gen 22300 vertex\n",
      "gen 22400 vertex\n",
      "[5, 9, 10] done\n",
      "now running [5, 10]\n",
      "gen 22500 vertex\n",
      "gen 22600 vertex\n",
      "[5, 10] done\n",
      "now running [11]\n",
      "gen 22700 vertex\n",
      "gen 22800 vertex\n",
      "[11] done\n",
      "now running [12]\n",
      "gen 22900 vertex\n",
      "gen 23000 vertex\n",
      "[12] done\n",
      "now running [13]\n",
      "gen 23100 vertex\n",
      "gen 23200 vertex\n",
      "[13] done\n"
     ]
    }
   ],
   "source": [
    "count_n = 0\n",
    "for dict_index in range(0,len(all_feature_dict)):\n",
    "    F_P = all_feature_dict[dict_index]\n",
    "    running_f = F_P[0]\n",
    "    print(f'now running {running_f}')\n",
    "    AUO_coalitions, _, _ = generate_partition(F_P) \n",
    "    collist = [i.tolist() for i in AUO_coalitions]\n",
    "    colname = [tuple(i) for i in collist]\n",
    "    vertex_df = pd.DataFrame(columns=colname)\n",
    "    vertices_fl = f'C:/Users/User/Desktop/folder/pyfile/shap_residual/savedata/E_vi_feature{running_f}.pkl'\n",
    "    for i_index in range(0,50):\n",
    "        #print(f'index = {i_index}')\n",
    "        instance = sample_df.iloc[i_index]\n",
    "        std_instance = (instance - df_mean) / df_std\n",
    "        coalition_estimated_values = {}\n",
    "        #print(f'coalition_estimated_values_start = {coalition_estimated_values}')\n",
    "        eval_df = df.sample(n=1000)  #不斷sample\n",
    "        std_eval_df = (eval_df - df_mean) / df_std\n",
    "        base_mean, details = model_inference(std_eval_df)\n",
    "        #print(f'Base mean: {base_mean}')\n",
    "        for coalition in AUO_coalitions: \n",
    "            vi_df = std_eval_df.copy()  #用copy()才不會去更改到原始的dataframe\n",
    "            if len(coalition)!=0:\n",
    "                vi_df.iloc[:,coalition] = instance.iloc[coalition] \n",
    "                exp, details = model_inference(vi_df)         \n",
    "            #print(f'coalition = {coalition}')\n",
    "            #print(vi_df.head(3))\n",
    "            elif len(coalition)==0:\n",
    "                exp = base_mean\n",
    "            #print(f'exp = {exp}')\n",
    "            coalition_estimated_values[tuple(coalition)] =  exp - base_mean\n",
    "            #print(f'coalition_estimated_values[tuple(coalition)] = {coalition_estimated_values[tuple(coalition)]}')\n",
    "            count_n += 1  \n",
    "            if count_n % 100 == 0:\n",
    "                print(f\"gen {count_n} vertex\")\n",
    "        #print(f'coalition_estimated_values = {coalition_estimated_values}')\n",
    "        instance_df = pd.DataFrame([coalition_estimated_values])\n",
    "        vertex_df = pd.concat([vertex_df, instance_df], ignore_index=True)\n",
    "    with open(vertices_fl, 'wb') as f:\n",
    "        pickle.dump(vertex_df, f)\n",
    "        print(f'{running_f} done')          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ece301d2-41f7-41d7-b856-23650edc11d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 16)\n"
     ]
    }
   ],
   "source": [
    "print(vertex_df.shape)\n",
    "with open('vertices_fl', 'wb') as f:\n",
    "    pickle.dump(vertex_df, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
